{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f6eebe",
   "metadata": {},
   "source": [
    "# Running an LLM on your own laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec324d3b",
   "metadata": {},
   "source": [
    "In this notebook, we're going to learn how to run a Hugging Face LLM on our own machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da567b",
   "metadata": {},
   "source": [
    "## Download the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3eebf",
   "metadata": {},
   "source": [
    "We're going to write some code to manually download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fc34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d8f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_API_KEY = os.environ.get(\"HUGGING_FACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"lmsys/fastchat-t5-3b-v1.0\" ## trained on 3B parameters, primary intended use as a chatbot.\n",
    "filenames = [\n",
    "        \"pytorch_model.bin\", \"added_tokens.json\", \"config.json\", \"generation_config.json\", \n",
    "        \"special_tokens_map.json\", \"spiece.model\", \"tokenizer_config.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d119ea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\pytorch_model.bin : pytorch_model.bin\n",
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\added_tokens.json : added_tokens.json\n",
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\config.json : config.json\n",
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\generation_config.json : generation_config.json\n",
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\special_tokens_map.json : special_tokens_map.json\n",
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\spiece.model : spiece.model\n",
      "C:\\Users\\Inito\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\tokenizer_config.json : tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "for i in filenames:\n",
    "    downloaded_model_path = hf_hub_download(repo_id = model_id, filename = i , token = HUGGING_FACE_API_KEY)\n",
    "    print(f'{downloaded_model_path + \" : \" + i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38998698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inito\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db14a9af77f649089485c89556108d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, legacy=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipeline = pipeline(\"text2text-generation\", model=model, device=-1, tokenizer=tokenizer, max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f4c90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<pad> Apache Kafka is a popular open source message broker that is used for streaming and aggregating data from multiple sources. Some of its competitors include Apache Spark, Apache Storm, Apache Flume, and Apache Flink.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"What are competitors to Apache Kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807c048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<pad> tango waltz and samba'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"Name any three danceforms?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f17a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<pad> iran'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"Which country name starts with a letter I?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf40648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\"Who is Mr. Barak Obama?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\"What is the scientific name of humans?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7abfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912d5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead00d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cb15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d9bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
